{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Jeehyun\\ECE6780\\Data\\vgg\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/PC/Jeehyun/ECE6780/Data/vgg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import json\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Lambda, Conv2DTranspose\n",
    "from keras.layers import Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nuclei_feat(mag):\n",
    "    nuc_dir = 'C:/Users/PC/Jeehyun/ECE6780/Data/nuc_Feature/'\n",
    "\n",
    "    nuc_file_name = nuc_dir+ 'bach_mp_nuclei_feature_new_2.mat'\n",
    "    nuc_data = []\n",
    "    with h5py.File(nuc_file_name) as f:\n",
    "        for column in f['feature']:\n",
    "            row_data = []\n",
    "            for row_number in range(len(column)):            \n",
    "                row_data.append(f[column[row_number]][:])   \n",
    "            nuc_data.append(row_data)\n",
    "                    \n",
    "    Nuc_feat = np.array(nuc_data)\n",
    "    del nuc_data\n",
    "    \n",
    "    Nuc_feat = Nuc_feat.reshape(len(Nuc_feat), 256,256,1)\n",
    "    \n",
    "    Nuc_feat_sc = nuc_scaler(Nuc_feat)\n",
    "    \n",
    "    return Nuc_feat_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuc_scaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    data = data.reshape((len(data),256*256))\n",
    "    scaler.fit(data)\n",
    "    data_sc = scaler.transform(data)\n",
    "    data_sc = data_sc.reshape((len(data),256, 256,1))\n",
    "    return data_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_feat(mag):\n",
    "    pca_dir = 'C:/Users/PC/Jeehyun/ECE6780/Data/PCA_Feature/'\n",
    "\n",
    "    pca_file_name = pca_dir+ 'bach_pca_feature_new_2.mat'\n",
    "    pca_data = []\n",
    "    with h5py.File(pca_file_name) as f:\n",
    "        for column in f['feature']:\n",
    "            pca_data.append(column)\n",
    "                    \n",
    "    PCA_data = np.array(pca_data)\n",
    "    \n",
    "    PCA_data_sc = pca_scaler(PCA_data)    \n",
    "    del PCA_data\n",
    "    \n",
    "    return PCA_data_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_scaler(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    data_sc = scaler.transform(data)\n",
    "    return data_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_feat(mag):\n",
    "    vgg_BACH = np.load('fine_bottleneck_feat_bach_2_' + mag +'.npy')\n",
    "    return vgg_BACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Model(mag):    \n",
    "    #model_name = 'Final_concat_Model_' + mag\n",
    "    model_name = 'Final_concat_Model_t2_' + mag\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(model_name + '.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    model.compile(optimizer='sgd',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Data(mag):\n",
    "    bach_b_test, bach_m_test = 100, 200\n",
    "    nb_bach_test =  bach_b_test + bach_m_test\n",
    "    test_labels = np.array([0] * bach_b_test + [1] * bach_m_test)   \n",
    "    \n",
    "    Nuc_test = Nuclei_feat(mag)\n",
    "    PCA_test = PCA_feat(mag)\n",
    "    VGG_test = VGG_feat(mag)\n",
    "    return Nuc_test,PCA_test,VGG_test, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "300/300 [==============================] - 0s 721us/step\n",
      "\n",
      " BACH Test accuracy: 0.6000000238418579\n",
      "Loaded model from disk\n",
      "300/300 [==============================] - 0s 717us/step\n",
      "\n",
      " BACH Test accuracy: 0.6166666746139526\n",
      "Loaded model from disk\n",
      "300/300 [==============================] - 0s 724us/step\n",
      "\n",
      " BACH Test accuracy: 0.5799999833106995\n",
      "Loaded model from disk\n",
      "300/300 [==============================] - 0s 727us/step\n",
      "\n",
      " BACH Test accuracy: 0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "mag_fact = '40'\n",
    "loaded_model = Load_Model(mag_fact)\n",
    "Nuc_bach,PCA_bach,VGG_bach, Labels_bach = Load_Data(mag_fact)\n",
    "pred = loaded_model.predict(x = [Nuc_bach, PCA_bach, VGG_bach])    \n",
    "accuracy = loaded_model.evaluate(x = [Nuc_bach, PCA_bach, VGG_bach], y = Labels_bach)\n",
    "print('\\n', 'BACH Test accuracy:', accuracy[1])\n",
    "\n",
    "mag_fact = '100'\n",
    "loaded_model = Load_Model(mag_fact)\n",
    "Nuc_bach,PCA_bach,VGG_bach, Labels_bach = Load_Data(mag_fact)\n",
    "pred = loaded_model.predict(x = [Nuc_bach, PCA_bach, VGG_bach])    \n",
    "accuracy = loaded_model.evaluate(x = [Nuc_bach, PCA_bach, VGG_bach], y = Labels_bach)\n",
    "print('\\n', 'BACH Test accuracy:', accuracy[1])\n",
    "\n",
    "mag_fact = '200'\n",
    "loaded_model = Load_Model(mag_fact)\n",
    "Nuc_bach,PCA_bach,VGG_bach, Labels_bach = Load_Data(mag_fact)\n",
    "pred = loaded_model.predict(x = [Nuc_bach, PCA_bach, VGG_bach])    \n",
    "accuracy = loaded_model.evaluate(x = [Nuc_bach, PCA_bach, VGG_bach], y = Labels_bach)\n",
    "print('\\n', 'BACH Test accuracy:', accuracy[1])\n",
    "\n",
    "mag_fact = '400'\n",
    "loaded_model = Load_Model(mag_fact)\n",
    "Nuc_bach,PCA_bach,VGG_bach, Labels_bach = Load_Data(mag_fact)\n",
    "pred = loaded_model.predict(x = [Nuc_bach, PCA_bach, VGG_bach])    \n",
    "accuracy = loaded_model.evaluate(x = [Nuc_bach, PCA_bach, VGG_bach], y = Labels_bach)\n",
    "print('\\n', 'BACH Test accuracy:', accuracy[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
