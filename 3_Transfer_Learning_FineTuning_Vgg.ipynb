{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Jeehyun\\ECE6780\\Data\\vgg\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/PC/Jeehyun/ECE6780/Data/vgg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "def gen_name(mag_fact):\n",
    "    train_dir = 'breast_' + mag_fact + '_split/train'\n",
    "    val_dir = 'breast_' + mag_fact + '_split/val'\n",
    "    model_name = 'bottleneck_fc_model_' + mag_fact + '.h5'\n",
    "    return train_dir, val_dir, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_train():\n",
    "    model_new_name = 'TL_model_' + mag_fact\n",
    "    top_model_weights_path = model_new_name + '.h5'\n",
    "    model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "    print('Model loaded.')\n",
    "\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256))\n",
    "    top_model.add(Activation('relu'))\n",
    "    top_model.add(Dropout(0.25))\n",
    "    top_model.add(Dense(1))\n",
    "    top_model.add(Activation('sigmoid'))\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    newmodel = Model(input= model.input, output= top_model(model.output))\n",
    "\n",
    "    for layer in newmodel.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    newmodel.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    newmodel.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "    \n",
    "    fine_features_train = newmodel.predict_generator(train_generator, nb_train_samples//batch_size)\n",
    "    np.save(open('fine_features_train' + mag_fact +'.npy', 'wb'), fine_features_train)\n",
    "\n",
    "    fine_features_val = newmodel.predict_generator(validation_generator, nb_train_samples//batch_size)\n",
    "    np.save(open('fine_features_val' + mag_fact +'.npy', 'wb'), fine_features_val)\n",
    "\n",
    "    model_new_name = 'tuned_TL_' + mag_fact\n",
    "    model_json = newmodel.to_json()\n",
    "\n",
    "    with open(model_new_name + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        newmodel.save_weights(model_new_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1670 images belonging to 2 classes.\n",
      "Found 311 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, validation_data=<keras.pre..., steps_per_epoch=1670, validation_steps=311)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1670/1670 [==============================] - 814s 487ms/step - loss: 0.5654 - accuracy: 0.7263 - val_loss: 2.6413 - val_accuracy: 0.5723\n",
      "Epoch 2/20\n",
      "1670/1670 [==============================] - 862s 516ms/step - loss: 0.4790 - accuracy: 0.7832 - val_loss: 0.5219 - val_accuracy: 0.6527\n",
      "Epoch 3/20\n",
      "1670/1670 [==============================] - 761s 456ms/step - loss: 0.4120 - accuracy: 0.8228 - val_loss: 0.0747 - val_accuracy: 0.7621\n",
      "Epoch 4/20\n",
      "1670/1670 [==============================] - 696s 417ms/step - loss: 0.3600 - accuracy: 0.8509 - val_loss: 0.2391 - val_accuracy: 0.8875\n",
      "Epoch 5/20\n",
      "1670/1670 [==============================] - 697s 417ms/step - loss: 0.3304 - accuracy: 0.8653 - val_loss: 3.9545e-07 - val_accuracy: 0.8360\n",
      "Epoch 6/20\n",
      "1670/1670 [==============================] - 697s 417ms/step - loss: 0.3089 - accuracy: 0.8713 - val_loss: 0.0226 - val_accuracy: 0.8810\n",
      "Epoch 7/20\n",
      "1670/1670 [==============================] - 697s 417ms/step - loss: 0.2576 - accuracy: 0.8970 - val_loss: 0.0142 - val_accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "1670/1670 [==============================] - 698s 418ms/step - loss: 0.2506 - accuracy: 0.9042 - val_loss: 9.1868e-07 - val_accuracy: 0.9100\n",
      "Epoch 9/20\n",
      "1670/1670 [==============================] - 695s 416ms/step - loss: 0.2142 - accuracy: 0.9198 - val_loss: 3.2824e-04 - val_accuracy: 0.9260\n",
      "Epoch 10/20\n",
      "1670/1670 [==============================] - 694s 415ms/step - loss: 0.1937 - accuracy: 0.9251 - val_loss: 0.0181 - val_accuracy: 0.9293\n",
      "Epoch 11/20\n",
      "1670/1670 [==============================] - 694s 416ms/step - loss: 0.1925 - accuracy: 0.9281 - val_loss: 1.3569e-04 - val_accuracy: 0.7524\n",
      "Epoch 12/20\n",
      "1670/1670 [==============================] - 692s 415ms/step - loss: 0.1628 - accuracy: 0.9359 - val_loss: 3.7973e-04 - val_accuracy: 0.9068\n",
      "Epoch 13/20\n",
      "1670/1670 [==============================] - 693s 415ms/step - loss: 0.1432 - accuracy: 0.9347 - val_loss: 0.0475 - val_accuracy: 0.9678\n",
      "Epoch 14/20\n",
      "1670/1670 [==============================] - 693s 415ms/step - loss: 0.1389 - accuracy: 0.9431 - val_loss: 0.0694 - val_accuracy: 0.9582\n",
      "Epoch 15/20\n",
      "1670/1670 [==============================] - 693s 415ms/step - loss: 0.1455 - accuracy: 0.9389 - val_loss: 0.0411 - val_accuracy: 0.9775\n",
      "Epoch 16/20\n",
      "1670/1670 [==============================] - 693s 415ms/step - loss: 0.1150 - accuracy: 0.9581 - val_loss: 0.0165 - val_accuracy: 0.9550\n",
      "Epoch 17/20\n",
      "1670/1670 [==============================] - 693s 415ms/step - loss: 0.1185 - accuracy: 0.9533 - val_loss: 4.2776e-04 - val_accuracy: 0.9775\n",
      "Epoch 18/20\n",
      "1670/1670 [==============================] - 692s 414ms/step - loss: 0.1074 - accuracy: 0.9569 - val_loss: 9.9832e-05 - val_accuracy: 0.9614\n",
      "Epoch 19/20\n",
      "1670/1670 [==============================] - 691s 414ms/step - loss: 0.0930 - accuracy: 0.9605 - val_loss: 3.0325e-04 - val_accuracy: 0.9646\n",
      "Epoch 20/20\n",
      "1670/1670 [==============================] - 691s 414ms/step - loss: 0.0849 - accuracy: 0.9701 - val_loss: 9.8710e-06 - val_accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "mag_fact = '40'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 500, 1170, 100, 137, 137, 174\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 20\n",
    "fine_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 1752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 323 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., steps_per_epoch=1752, validation_steps=323)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1752/1752 [==============================] - 771s 440ms/step - loss: 0.5901 - accuracy: 0.7072 - val_loss: 1.1405 - val_accuracy: 0.5820\n",
      "Epoch 2/10\n",
      "1752/1752 [==============================] - 728s 416ms/step - loss: 0.5285 - accuracy: 0.7146 - val_loss: 1.3731 - val_accuracy: 0.8111\n",
      "Epoch 3/10\n",
      "1752/1752 [==============================] - 729s 416ms/step - loss: 0.4412 - accuracy: 0.7803 - val_loss: 0.9541 - val_accuracy: 0.6533\n",
      "Epoch 4/10\n",
      "1752/1752 [==============================] - 729s 416ms/step - loss: 0.3633 - accuracy: 0.8402 - val_loss: 0.0460 - val_accuracy: 0.7461\n",
      "Epoch 5/10\n",
      "1752/1752 [==============================] - 728s 416ms/step - loss: 0.3224 - accuracy: 0.8556 - val_loss: 0.4650 - val_accuracy: 0.8545\n",
      "Epoch 6/10\n",
      "1752/1752 [==============================] - 729s 416ms/step - loss: 0.3042 - accuracy: 0.8710 - val_loss: 1.5785e-05 - val_accuracy: 0.8916\n",
      "Epoch 7/10\n",
      "1752/1752 [==============================] - 730s 416ms/step - loss: 0.2524 - accuracy: 0.9081 - val_loss: 0.0439 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "1752/1752 [==============================] - 729s 416ms/step - loss: 0.2393 - accuracy: 0.9024 - val_loss: 9.6587e-06 - val_accuracy: 0.8978\n",
      "Epoch 9/10\n",
      "1752/1752 [==============================] - 730s 416ms/step - loss: 0.2169 - accuracy: 0.9087 - val_loss: 0.0554 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "1752/1752 [==============================] - 729s 416ms/step - loss: 0.2019 - accuracy: 0.9178 - val_loss: 1.2963e-05 - val_accuracy: 0.8390\n"
     ]
    }
   ],
   "source": [
    "mag_fact = '100'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 515, 1237, 100, 145, 135, 188\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "fine_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 1688 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., steps_per_epoch=1688, validation_steps=315)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 753s 446ms/step - loss: 0.5818 - accuracy: 0.7079 - val_loss: 0.3368 - val_accuracy: 0.5651\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 703s 416ms/step - loss: 0.5307 - accuracy: 0.7168 - val_loss: 1.2432 - val_accuracy: 0.6857\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 703s 416ms/step - loss: 0.4550 - accuracy: 0.7790 - val_loss: 0.7935 - val_accuracy: 0.8476\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 702s 416ms/step - loss: 0.4025 - accuracy: 0.8122 - val_loss: 0.5595 - val_accuracy: 0.7905\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 703s 416ms/step - loss: 0.3322 - accuracy: 0.8590 - val_loss: 0.0331 - val_accuracy: 0.7937\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 705s 418ms/step - loss: 0.3084 - accuracy: 0.8596 - val_loss: 3.7536 - val_accuracy: 0.7746\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 703s 417ms/step - loss: 0.2656 - accuracy: 0.8803 - val_loss: 0.4357 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 708s 419ms/step - loss: 0.2613 - accuracy: 0.8892 - val_loss: 0.9933 - val_accuracy: 0.9111\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 711s 421ms/step - loss: 0.2350 - accuracy: 0.9034 - val_loss: 1.2725 - val_accuracy: 0.8413\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 705s 418ms/step - loss: 0.1976 - accuracy: 0.9129 - val_loss: 0.0276 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-320627b607f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfine_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-928dd1cdeead>\u001b[0m in \u001b[0;36mfine_train\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fine_features_train'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmag_fact\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfine_features_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mfine_features_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_train_samples\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fine_features_val'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmag_fact\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfine_features_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1578\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mag_fact = '200'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 498, 1190, 100, 139, 137, 178\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "fine_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 1502 images belonging to 2 classes.\n",
      "Found 287 images belonging to 2 classes."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., steps_per_epoch=1502, validation_steps=287)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1502/1502 [==============================] - 630s 420ms/step - loss: 0.6212 - accuracy: 0.6877 - val_loss: 1.1308 - val_accuracy: 0.5122\n",
      "Epoch 2/10\n",
      "1502/1502 [==============================] - 714s 476ms/step - loss: 0.6160 - accuracy: 0.6897 - val_loss: 0.3270 - val_accuracy: 0.5122\n",
      "Epoch 3/10\n",
      "1502/1502 [==============================] - 654s 435ms/step - loss: 0.5634 - accuracy: 0.7270 - val_loss: 0.2836 - val_accuracy: 0.7735\n",
      "Epoch 4/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.4823 - accuracy: 0.7830 - val_loss: 1.5560 - val_accuracy: 0.5122\n",
      "Epoch 5/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.4571 - accuracy: 0.7929 - val_loss: 0.1561 - val_accuracy: 0.6307\n",
      "Epoch 6/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.3755 - accuracy: 0.8469 - val_loss: 0.0884 - val_accuracy: 0.6341\n",
      "Epoch 7/10\n",
      "1502/1502 [==============================] - 628s 418ms/step - loss: 0.3728 - accuracy: 0.8415 - val_loss: 1.1213 - val_accuracy: 0.7631\n",
      "Epoch 8/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.3179 - accuracy: 0.8668 - val_loss: 0.1097 - val_accuracy: 0.8258\n",
      "Epoch 9/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.2815 - accuracy: 0.8908 - val_loss: 0.5087 - val_accuracy: 0.8815\n",
      "Epoch 10/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.2624 - accuracy: 0.9035 - val_loss: 0.0144 - val_accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "mag_fact = '400'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 470, 1032, 100, 124, 140, 147\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "fine_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_conn(mag):\n",
    "    train_dir = 'breast_' + mag + '_split/train'\n",
    "    val_dir = 'breast_' + mag + '_split/val'\n",
    "    test_dir = 'breast_' + mag + '_split/test'\n",
    "\n",
    "    if mag == '40':\n",
    "        b_train, m_train, b_test, m_test, b_val, m_val = 500, 1170, 100, 137, 137, 174\n",
    "    if mag == '100':\n",
    "        b_train, m_train, b_test, m_test, b_val, m_val = 515, 1237, 100, 145, 135, 188\n",
    "    if mag == '200':\n",
    "        b_train, m_train, b_test, m_test, b_val, m_val = 498, 1190, 100, 139, 137, 178\n",
    "    if mag == '400':\n",
    "        b_train, m_train, b_test, m_test, b_val, m_val = 470, 1032, 100, 124, 140, 147        \n",
    "    \n",
    "    n_train =  b_train + m_train\n",
    "    n_val =  b_val + m_val\n",
    "    n_test =  b_test + m_test\n",
    "\n",
    "    train_labels = np.array([0] * b_train + [1] * m_train)\n",
    "    val_labels = np.array([0] * b_val + [1] * m_val)\n",
    "    test_labels = np.array([0] * b_test + [1] * m_test)\n",
    "    return train_dir, val_dir, test_dir, n_train, n_val, n_test, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_feat(mag):\n",
    "    vgg_train = np.load('fine_bottleneck_feat_train_' + mag +'.npy')\n",
    "    vgg_val = np.load('fine_bottleneck_feat_val_' + mag +'.npy')\n",
    "    vgg_test = np.load('fine_bottleneck_feat_test_' + mag +'.npy')\n",
    "    return vgg_train, vgg_val, vgg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_breakhis(mag):\n",
    "    train_dir, val_dir, test_dir, nb_train, nb_val, nb_test, train_labels, val_labels, test_labels = mag_conn(mag)\n",
    "    VGG_train, VGG_val, VGG_test = VGG_feat(mag)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    train_generator = test_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    val_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "        \n",
    "    model_name = 'tuned_TL_' + mag\n",
    "    # load json and create model\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(model_name + '.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    model.compile(optimizer='sgd',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    train_score = model.evaluate_generator(train_generator)\n",
    "    val_score = model.evaluate_generator(val_generator)\n",
    "    test_score = model.evaluate_generator(test_generator)\n",
    "    print('\\n', 'BreakHis Train accuracy:', train_score[1])\n",
    "    print('\\n', 'BreakHis Validation accuracy:', val_score[1])\n",
    "    print('\\n', 'BreakHis Test accuracy:', test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 1752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 323 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., steps_per_epoch=1502, validation_steps=287)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1502/1502 [==============================] - 629s 419ms/step - loss: 0.5746 - accuracy: 0.7150 - val_loss: 0.8920 - val_accuracy: 0.5819\n",
      "Epoch 2/10\n",
      "1502/1502 [==============================] - 628s 418ms/step - loss: 0.5127 - accuracy: 0.7204 - val_loss: 0.7327 - val_accuracy: 0.6655\n",
      "Epoch 3/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.4404 - accuracy: 0.7876 - val_loss: 0.3171 - val_accuracy: 0.7735\n",
      "Epoch 4/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.3848 - accuracy: 0.8296 - val_loss: 6.0305e-04 - val_accuracy: 0.8432\n",
      "Epoch 5/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.3444 - accuracy: 0.8515 - val_loss: 0.2625 - val_accuracy: 0.7700\n",
      "Epoch 6/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.2988 - accuracy: 0.8675 - val_loss: 0.2165 - val_accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.2633 - accuracy: 0.8768 - val_loss: 3.7801e-04 - val_accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.2695 - accuracy: 0.8915 - val_loss: 0.0188 - val_accuracy: 0.8955\n",
      "Epoch 9/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.2240 - accuracy: 0.9055 - val_loss: 4.7396e-04 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.2153 - accuracy: 0.9148 - val_loss: 0.0214 - val_accuracy: 0.9199\n",
      "Found 245 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Test accuracy: 0.9387755393981934\n",
      "Model loaded.\n",
      "Found 1502 images belonging to 2 classes.\n",
      "Found 287 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., steps_per_epoch=1502, validation_steps=287)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.6217 - accuracy: 0.6871 - val_loss: 0.3830 - val_accuracy: 0.5122\n",
      "Epoch 2/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.6208 - accuracy: 0.6871 - val_loss: 1.0726 - val_accuracy: 0.5122\n",
      "Epoch 3/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.5934 - accuracy: 0.7084 - val_loss: 1.1950 - val_accuracy: 0.5122\n",
      "Epoch 4/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.5380 - accuracy: 0.7490 - val_loss: 2.1269 - val_accuracy: 0.5645\n",
      "Epoch 5/10\n",
      "1502/1502 [==============================] - 627s 418ms/step - loss: 0.4560 - accuracy: 0.8003 - val_loss: 0.1885 - val_accuracy: 0.6411\n",
      "Epoch 6/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.3977 - accuracy: 0.8349 - val_loss: 0.3106 - val_accuracy: 0.8606\n",
      "Epoch 7/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.3780 - accuracy: 0.8349 - val_loss: 0.1026 - val_accuracy: 0.7178\n",
      "Epoch 8/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.3435 - accuracy: 0.8589 - val_loss: 0.0280 - val_accuracy: 0.7875\n",
      "Epoch 9/10\n",
      "1502/1502 [==============================] - 626s 417ms/step - loss: 0.3121 - accuracy: 0.8808 - val_loss: 0.0242 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "1502/1502 [==============================] - 627s 417ms/step - loss: 0.2857 - accuracy: 0.8855 - val_loss: 0.0107 - val_accuracy: 0.9164\n",
      "Found 224 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Test accuracy: 0.8839285969734192\n"
     ]
    }
   ],
   "source": [
    "mag_fact = '100'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 470, 1032, 100, 124, 140, 147\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "fine_train()\n",
    "test_breakhis('100')\n",
    "\n",
    "mag_fact = '400'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 470, 1032, 100, 124, 140, 147\n",
    "\n",
    "nb_train_samples =  b_train + m_train\n",
    "nb_validation_samples =  b_val + m_val\n",
    "\n",
    "train_data_dir, validation_data_dir, model_name = gen_name(mag_fact)\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "fine_train()\n",
    "test_breakhis('400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1670 images belonging to 2 classes.\n",
      "Found 311 images belonging to 2 classes.\n",
      "Found 237 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Train accuracy: 0.9904191493988037\n",
      "\n",
      " BreakHis Validation accuracy: 0.9742765426635742\n",
      "\n",
      " BreakHis Test accuracy: 0.9535865187644958\n",
      "Found 1752 images belonging to 2 classes.\n",
      "Found 323 images belonging to 2 classes.\n",
      "Found 245 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Train accuracy: 0.943493127822876\n",
      "\n",
      " BreakHis Validation accuracy: 0.9164086580276489\n",
      "\n",
      " BreakHis Test accuracy: 0.9387755393981934\n",
      "Found 1688 images belonging to 2 classes.\n",
      "Found 315 images belonging to 2 classes.\n",
      "Found 239 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Train accuracy: 0.9911137223243713\n",
      "\n",
      " BreakHis Validation accuracy: 0.9555555582046509\n",
      "\n",
      " BreakHis Test accuracy: 0.9205020666122437\n",
      "Found 1502 images belonging to 2 classes.\n",
      "Found 287 images belonging to 2 classes.\n",
      "Found 224 images belonging to 2 classes.\n",
      "Loaded model from disk\n",
      "\n",
      " BreakHis Train accuracy: 0.9307590126991272\n",
      "\n",
      " BreakHis Validation accuracy: 0.9163762927055359\n",
      "\n",
      " BreakHis Test accuracy: 0.8839285969734192\n"
     ]
    }
   ],
   "source": [
    "test_breakhis('40')\n",
    "test_breakhis('100')\n",
    "test_breakhis('200')\n",
    "test_breakhis('400')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
