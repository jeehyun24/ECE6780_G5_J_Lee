{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Jeehyun\\ECE6780\\Data\\vgg\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/PC/Jeehyun/ECE6780/Data/vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import model_from_json\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_fact = '40'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 500, 1170, 100, 137, 137, 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_fact = '100'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 515, 1237, 100, 145, 135, 188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_fact = '200'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 498, 1190, 100, 139, 137, 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_fact = '400'\n",
    "b_train, m_train, b_test, m_test, b_val, m_val = 470, 1032, 100, 124, 140, 147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'breast_' + mag_fact + '_split/train'\n",
    "subfolders = os.listdir(train_dir)\n",
    "\n",
    "TL_imgNames = []\n",
    "for subf in subfolders:\n",
    "    tumfolders = os.listdir(train_dir + '/' + subf)\n",
    "    for m in tumfolders:\n",
    "        m = m.split('.')[0] + '.tif'\n",
    "        TL_imgNames.append(m)\n",
    "        \n",
    "with open('breakhis_name.csv', newline='') as csvfile:\n",
    "    dataNames = list(csv.reader(csvfile))\n",
    "\n",
    "FileNames = np.array(dataNames)\n",
    "del dataNames\n",
    "\n",
    "rows = 0\n",
    "fnames = []\n",
    "while rows < len(FileNames):  \n",
    "    names = FileNames[rows][0]\n",
    "    fnames.append(names)\n",
    "    rows += 1\n",
    "del FileNames\n",
    "\n",
    "DataInd = []\n",
    "k=0\n",
    "while k < len(TL_imgNames):\n",
    "    d = fnames.index(TL_imgNames[k])\n",
    "    DataInd.append(d)\n",
    "    k += 1 \n",
    "    \n",
    "    \n",
    "with open('DataInd_' + mag_fact + '.txt', 'w') as f:\n",
    "    for item in DataInd:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = 'breast_' + mag_fact + '_split/val'\n",
    "subfolders = os.listdir(val_dir)\n",
    "\n",
    "TL_imgNames = []\n",
    "for subf in subfolders:\n",
    "    tumfolders = os.listdir(val_dir + '/' + subf)\n",
    "    for m in tumfolders:\n",
    "        m = m.split('.')[0] + '.tif'\n",
    "        TL_imgNames.append(m)\n",
    "                \n",
    "with open('breakhis_name.csv', newline='') as csvfile:\n",
    "    dataNames = list(csv.reader(csvfile))\n",
    "\n",
    "FileNames = np.array(dataNames)\n",
    "del dataNames\n",
    "\n",
    "rows = 0\n",
    "fnames = []\n",
    "while rows < len(FileNames):  \n",
    "    names = FileNames[rows][0]\n",
    "    fnames.append(names)\n",
    "    rows += 1\n",
    "del FileNames\n",
    "\n",
    "DataInd = []\n",
    "k=0\n",
    "while k < len(TL_imgNames):\n",
    "    d = fnames.index(TL_imgNames[k])\n",
    "    DataInd.append(d)\n",
    "    k += 1 \n",
    "    \n",
    "with open('DataInd_val_' + mag_fact + '.txt', 'w') as f:\n",
    "    for item in DataInd:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'breast_' + mag_fact + '_split/test'\n",
    "subfolders = os.listdir(test_dir)\n",
    "\n",
    "TL_imgNames = []\n",
    "for subf in subfolders:\n",
    "    tumfolders = os.listdir(test_dir + '/' + subf)\n",
    "    for m in tumfolders:\n",
    "        m = m.split('.')[0] + '.tif'\n",
    "        TL_imgNames.append(m)\n",
    "                \n",
    "with open('breakhis_name.csv', newline='') as csvfile:\n",
    "    dataNames = list(csv.reader(csvfile))\n",
    "\n",
    "FileNames = np.array(dataNames)\n",
    "del dataNames\n",
    "\n",
    "rows = 0\n",
    "fnames = []\n",
    "while rows < len(FileNames):  \n",
    "    names = FileNames[rows][0]\n",
    "    fnames.append(names)\n",
    "    rows += 1\n",
    "del FileNames\n",
    "\n",
    "DataInd = []\n",
    "k=0\n",
    "while k < len(TL_imgNames):\n",
    "    d = fnames.index(TL_imgNames[k])\n",
    "    DataInd.append(d)\n",
    "    k += 1 \n",
    "    \n",
    "with open('DataInd_test_' + mag_fact + '.txt', 'w') as f:\n",
    "    for item in DataInd:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
